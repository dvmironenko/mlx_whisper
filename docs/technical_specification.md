# Техническая спецификация для MLX-Whisper REST API

## Обзор

MLX-Whisper — это высокопроизводительный сервис транскрибации аудио, использующий оптимизированную модель Whisper от Apple (MLX-Whisper) для обработки аудиофайлов на системах macOS с чипами Apple Silicon. Сервис предоставляет как веб-интерфейс, так и REST‑API для преобразования речи в текст с поддержкой нескольких языков и гибкими параметрами обработки.

## Архитектура

### Системные компоненты

1. **FastAPI Web Server**: Ядро приложения, которое обрабатывает HTTP‑запросы и ответы  
2. **MLX-Whisper Integration**: Прямая интеграция с фреймворком Apple MLX для оптимизированного инференса  
3. **FFmpeg Audio Processing**: Преобразует аудиофайлы в требуемый WAV‑формат (16 kHz, моно)  
4. **Thread Pool Executor**: Управляет параллельными задачами транскрипции для оптимизации использования ресурсов  
5. **Web Interface**: HTML/JavaScript фронтенд для удобной загрузки файлов и отображения результатов  

### Технологический стек

- **Backend Framework**: FastAPI (Python 3.8+)  
- **MLX Integration**: mlx‑whisper (оптимизированная реализация Whisper от Apple)  
- **Audio Processing**: FFmpeg для конвертации форматов  
- **Frontend**: HTML, CSS, JavaScript со стилями, похожими на Bootstrap  
- **Deployment**: Uvicorn ASGI сервер  

## Структура проекта

```
mlx-whisper-api/
├── docs/                   # Директория документации
│   └── technical_specification.md  # Техническая спецификация  
├── models/                 # Файлы моделей MLX‑Whisper (config.json, weights.npz)
│   ├── whisper-tiny/
│   ├── whisper-base/ 
│   ├── whisper-small/
│   ├── whisper-medium/
│   ├── whisper-turbo/
│   └── whisper-large/
├── src/                    # Исходный код
│   ├── main.py             # Основной FastAPI‑приложение и логика транскрипции  
│   ├── requirements.txt    # Зависимости Python  
│   ├── static/             # Статические ресурсы (CSS)  
│   │   └── style.css       # Стили веб‑интерфейса  
│   └── templates/          # HTML шаблоны  
│       └── index.html      # Основной шаблон веб‑интерфейса  
├── tests/                  # Тестовые аудиофайлы  
│   ├── test.wav  
│   └── 2_5258335770527167268.ogg  
├── uploads/                # Временное хранилище файлов  
├── README.md               # Документация проекта и руководство пользователя  
└── .gitignore              # Конфигурация игнорирования файлов Git
```

## Основные функции

### Цепочка обработки аудио

1. **Валидация загрузки файла**:
   - Проверяет расширения файлов (.wav, .mp3, .m4a, .flac, .aac, .ogg, .wma, .webm, .mp4)  
   - Проверяет размер файла (максимум 5 ГБ)  
   - Удостоверяется в корректном формате файла  

2. **Преобразование формата аудио**:
   - Использует FFmpeg для преобразования аудиофайлов в WAV‑формат (16 kHz, моно)  
   - Сохраняет качество звука при совместимости с моделью Whisper  

3. **Обработка транскрипции**:
   - Поддерживает различные размеры моделей (tiny, base, small, medium, turbo, large)  
   - Обрабатывает задачи транскрибации и перевода  
   - Предоставляет временные метки слов при необходимости  
   - Обработка с учетом контекста предыдущего текста  

4. **Управление результатами**:
   - Хранит результаты транскрипции в виде текстовых файлов  
   - Отслеживает статус задачи с уникальными идентификаторами  
   - Предоставляет подробные метаданные о процессе обработки  

### Функции веб‑интерфейса

- Интуитивно понятная загрузка файлов через перетаскивание  
- Выбор языка (автоопределение или конкретный язык)  
- Выбор типа задачи (транскрибировать или перевести)  
- Настройка размера модели  
- Параметры для продвинутых пользователей  
- Отображение результатов в реальном времени с возможностью скачивания  

## API‑конечные точки

### Основная конечная точка транскрипции

```
POST /transcribe
```

**Параметры запроса**:
- `file` (обязательно): Аудиофайл для транскрипции
- `language` (необязательно): Код языка (ISO-639) — по умолчанию «ru»
- `task` (необязательно): Тип задачи («transcribe» или «translate») — по умолчанию «transcribe»
- `model` (необязательно): Размер модели Whisper — по умолчанию «large»
- `word_timestamps` (необязательно): Включить временные метки слов — по умолчанию true
- `condition_on_previous_text` (необязательно): Использовать предыдущий текст для контекста — по умолчанию true
- `no_speech_threshold` (необязательно): Порог для обнаружения отсутствия речи (значение по умолчанию 0.4)
- `hallucination_silence_threshold` (необязательно): Порог для обнаружения галлюцинаций/тишины (значение по умолчанию 0.8)
- `remove_silence` (необязательно): Удаление тишины в начале и конце аудио (true/false) — по умолчанию true
- `silence_threshold` (необязательно): Порог для обнаружения тишины (в dB, по умолчанию -60.0)
- `silence_duration` (необязательно): Минимальная длительность тишины для удаления (в секундах, по умолчанию 0.5)

**Формат ответа**:
```json
{
  "text": "Распознанный текст",
  "language": "ru",
  "model": "large",
  "task": "transcribe",
  "word_timestamps": true,
  "condition_on_previous_text": true,
  "no_speech_threshold": 0.4,
  "hallucination_silence_threshold": 0.8,
  "segments": [
    {
      "start": 0.0,
      "end": 5.0,
      "text": "Пример сегмента текста"
    }
  ],
  "uploaded_file": "job_id_filename.wav",
  "result_file": "job_id_filename.txt",
  "job_id": "уникальный_идентификатор_задачи",
  "duration": 12.34
}
```

### Дополнительные конечные точки

```
GET /health                    # Проверка работоспособности  
GET /models                    # Получить список поддерживаемых моделей  
GET /job/{job_id}              # Получить статус конкретной задачи  
GET /                          # Корневая конечная точка веб‑интерфейса
```

## Технические детали реализации

### Оптимизация памяти

1. **Обработка файлов порциями**:
   - Читает большие файлы по 8 КБ для предотвращения переполнения памяти  
   - Обрабатывает аудио данные в управляемых сегментах  

2. **Управление пулом потоков**:
   - Использует ThreadPoolExecutor с 2 рабочими потоками для параллельной обработки  
   - Предотвращает исчерпание ресурсов при одновременных запросах  

3. **Управление временными файлами**:
   - Создает уникальные идентификаторы задач для избежания конфликтов файлов  
   - Автоматически очищает временные файлы после обработки  

### Обработка ошибок и логирование

1. **Полная обработка ошибок**:
   - Валидация всех входных параметров перед обработкой  
   - Гибкая обработка ошибок конвертации FFmpeg  
   - Предоставление подробных сообщений об ошибках для отладки  

2. **Фреймворк логирования**:
   - Структурированное логирование для мониторинга и отладки  
   - Логирует завершение задач с информацией о времени выполнения  
   - Отслеживает ошибки обработки и исключения  

### Сериализация данных

1. **Сериализация JSON**:
   - Обрабатывает преобразование типов данных NumPy в нативные типы Python  
   - Корректно обрабатывает значения NaN и бесконечности в JSON‑выводе  
   - Реализует собственную логику сериализации для крайних случаев  

2. **Формат результата**:
   - Возвращает структурированный JSON со всеми релевантными метаданными  
   - Включает сегменты с временными отметками слов при включении  
   - Предоставляет идентификаторы задач для отслеживания статуса  

## Характеристики производительности

### Требования к ресурсам

- **Аппаратное обеспечение**: Mac с чипом Apple Silicon (M1/M2) обязательный  
- **Память**: Минимум 8 ГБ ОЗУ рекомендовано  
- **Хранилище**: Временное хранилище файлов в директории uploads  
- **Обработка**: Оптимизировано под нейронный процессор Apple  

### Сравнение производительности моделей

| Модель | Размер | Скорость | Точность |
|--------|--------|----------|----------|
| tiny   | ~39 МБ | Очень быстрая | Низкая |
| base   | ~74 МБ | Быстрая | Удовлетворительная |
| small  | ~249 МБ | Средняя | Хорошая |
| medium | ~769 МБ | Медленная | Высокая |
| turbo  | ~1.4 ГБ | Очень быстрая | Очень высокая |
| large  | ~3.1 ГБ | Медленная | Отличная |

### Цепочка обработки

1. **Загрузка файла**: Частичное чтение больших файлов  
2. **Преобразование формата**: Конвертация WAV с помощью FFmpeg (16 kHz, моно)  
3. **Инференс модели**: Транскрибация MLX‑Whisper с выбранной моделью  
4. **Обработка результата**: Сериализация в JSON с метаданными  
5. **Генерация вывода**: Создание текстового файла и отслеживание задачи  

## Соображения безопасности

1. **Валидация входных данных**:
   - Проверка расширений файлов, чтобы предотвратить вредоносные загрузки  
   - Ограничение размера файла для предотвращения исчерпания ресурсов  
   - Очистка всех входных параметров  

2. **Обработка файлов**:
   - Использование уникальных идентификаторов для предотвращения конфликтов файлов  
   - Очистка временных файлов после обработки  
   - Корректные права доступа к файлам  

3. **Безопасность API**:
   - Аутентификация не требуется (предназначено для локального использования)  
   - Ограничение частоты запросов через управление пулом потоков  
   - Безопасная обработка путей к файлам и идентификаторов  

## Требования к развертыванию

### Системные предварительные условия

- macOS с чипом Apple Silicon (M1/M2)  
- Python 3.8+  
- FFmpeg установлен для конвертации аудио форматов  
- Минимум 8 ГБ ОЗУ рекомендовано  

### Шаги установки

1. Клонировать репозиторий:
   ```bash
   git clone https://github.com/your-username/mlx-whisper.git
   cd mlx-whisper
   ```

2. Создать и активировать виртуальное окружение:
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   ```

3. Установить зависимости:
   ```bash
   pip install -r src/requirements.txt
   ```

4. Загрузить модели MLX‑Whisper:
   ```bash
   mkdir -p models/whisper-turbo
   # Загрузить config.json и weights.npz с Hugging Face
   ```

5. Запустить приложение:
   ```bash
   python src/main.py
   ```

### Производственные соображения

- Использовать Gunicorn вместо Uvicorn для продакшн‑развертывания  
- Реализовать правильную аутентификацию для публичных сервисов  
- Настроить соответствующие уровни логирования для мониторинга  
- Рассмотреть балансировку нагрузки при высоконагруженных сценариях  

## Тестирование и проверка

### Стратегия тестирования

1. **Модульное тестирование**:  
   - Тестирование отдельных функций для работы с файлами и конвертации  
   - Тесты проверки параметров модели  
   - Тестирование условий ошибок  

2. **Интеграционное тестирование**:  
   - Тесты полного цикла работы транскрипции  
   - Проверка корректности конвертации форматов аудио  
   - Верификация генерации файлов результатов  

3. **Тестирование производительности**:  
   - Проверка обработки больших файлов  
   - Тесты одновременных запросов  
   - Мониторинг использования памяти  

### Тестовые файлы

Проект включает тестовые аудиофайлы в каталоге `tests/` для ручной проверки:
- `test.wav`: Стандартный WAV‑файл  
- `2_5258335770527167268.ogg`: OGG‑аудиофайл для проверки формата  

## Устранение неполадок

### Распространенные проблемы и решения

1. **FFmpeg не найден**:  
   - Решение: Установить FFmpeg через Homebrew:
     ```bash
     brew install ffmpeg
     ```

2. **Файлы моделей отсутствуют**:  
   - Решение: Загрузить файлы моделей с Hugging Face в соответствующие директории  

3. **Проблемы с памятью**:  
   - Решение: Использовать более мелкие размеры моделей или обрабатывать файлы частями  

4. **Неподдерживаемые форматы аудио**:  
   - Решение: Убедиться, что файлы имеют одно из поддерживаемых расширений  

## Будущие улучшения

1. **Поддержка многоязычности**: Расширить поддержку языков за пределы русского/английского  
2. **Пакетная обработка**: Добавить возможность одновременной обработки нескольких файлов  
3. **Улучшенный веб‑интерфейс**: Улучшить UI с индикаторами прогресса в реальном времени  
4. **Аутентификация API**: Реализовать токен‑базированную аутентификацию для безопасных развертываний  
5. **Кэширование моделей**: Оптимизировать стратегии загрузки и кэширования моделей  
6. **Контейнеризация**: Предоставить поддержку Docker для упрощенного развертывания  

## Поддержка и обслуживание

1. **Обновления моделей**: Регулярные обновления моделей MLX‑Whisper с Hugging Face  
2. **Патчи безопасности**: Поддерживать зависимости актуальными с патчами безопасности  
3. **Мониторинг производительности**: Отслеживать системные ресурсы и корректировать настройки пула потоков  
4. **Обновления документации**: Держать техническую документацию актуальной с изменениями кода  

## Соответствие стандартам

### Стандарты разработки

- Стили кодирования PEP 8 для Python  
- Аннотации типов для всех параметров функций и возвращаемых значений  
- Правильная обработка исключений с HTTP‑кодами статуса  
- Асинхронные/ожидающие паттерны для операций ввода‑вывода  

### Стандарты данных

- Формат JSON для всех ответов API  
- Кодировка UTF‑8 для текстовых файлов  
- Стандартные форматы временных меток в сегментах  
- Последовательные соглашения по именованию для идентификаторов задач  

## Параметры модели Whisper

В этом разделе описаны параметры, которые можно передавать модели Whisper в MLX-Whisper:

### Основные параметры модели:
1. **`model_size`** - Размер модели Whisper для использования (tiny, small, medium, large)
2. **`language`** - Код целевого языка для транскрипции (автоопределение или конкретный язык, например "en", "ru", "fr")
3. **`task`** - Тип задачи для выполнения (transcribe или translate)

### Параметры обработки аудио:
1. **`beam_size`** - Размер beam search для декодирования (по умолчанию: 5)
2. **`temperature`** - Температура выборки, которая контролирует случайность вывода (по умолчанию: 0.0)
3. **`top_p`** - Параметр top-p sampling для управления разнообразием вывода
4. **`max_length`** - Максимальная длина последовательности для генерируемого текста

### Расширенные опции:
1. **`patience`** - Фактор терпимости beam search для управления поведением поиска
2. **`length_penalty`** - Коэффициент штрафа за длину для балансировки длины последовательности и вероятности
3. **`suppress_tokens`** - Токены для подавления во время генерации (для фильтрации определенных выводов)

### Параметры производительности и оборудования:
1. **`compute_type`** - Тип вычислений (fp32, fp16, int8) для управления числовыми характеристиками
2. **`threads`** - Количество CPU-потоков для использования при обработке
3. **`device`** - Устройство для запуска (cpu, gpu, mps) для выбора оборудования
4. **`batch_size`** - Размер пакета для обработки нескольких аудиофайлов одновременно

### Параметры вывода и форматирования:
1. **`word_timestamps`** - Флаг для включения временных меток слов в вывод
2. **`no_timestamps`** - Флаг для отключения генерации временных меток полностью
3. **`highlight`** - Опция для выделения транскрибированного текста в выводе

### Дополнительные функции:
1. **`best_of`** - Количество лучших кандидатов для рассмотрения при beam search
2. **`verbose`** - Включить подробный вывод для детального логирования

Эти параметры обеспечивают гибкость в контроле поведения модели, характеристик производительности и форматов вывода при использовании MLX-Whisper для задач транскрипции аудио.

## Ссылки

1. [MLX‑Whisper GitHub](https://github.com/ml-explore/mlx-whisper)  
2. [Фреймворк Apple MLX](https://github.com/ml-explore/mlx)  
3. [Документация FastAPI](https://fastapi.tiangolo.com/)  
4. [Документация FFmpeg](https://ffmpeg.org/documentation.html)  
5. [OpenAI Whisper Paper](https://arxiv.org/abs/2212.04356)  

Based on my research of the MLX-Whisper documentation and GitHub repository, here are the parameters that can be passed to the Whisper model in the MLX-Whisper implementation:                                                                                 
                                                                                                                                                                                                                                                                  
  MLX-Whisper Parameters                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                  
  Core Model Parameters:                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                  
  1. model_size - Size of the Whisper model to use (tiny, small, medium, large)
  2. language - Target language code for transcription (auto-detection or specific language like "en", "ru", "fr")
  3. task - Task type to perform (transcribe or translate)

  Audio Processing Parameters:

  1. beam_size - Beam search size for decoding (default: 5)
  2. temperature - Sampling temperature that controls output randomness (default: 0.0)
  3. top_p - Top-p sampling parameter for controlling output diversity
  4. max_length - Maximum sequence length for generated text

  Advanced Options:

  1. patience - Beam search patience factor for controlling search behavior
  2. length_penalty - Length penalty coefficient to balance sequence length and likelihood
  3. suppress_tokens - Tokens to suppress during generation (for filtering specific outputs)

  Performance and Hardware Parameters:

  1. compute_type - Computation type (fp32, fp16, int8) for numerical precision control
  2. threads - Number of CPU threads to use for processing
  3. device - Device to run on (cpu, gpu, mps) for hardware selection
  4. batch_size - Batch size for processing multiple audio files simultaneously

  Output and Formatting Options:

  1. word_timestamps - Flag to include word-level timestamps in output
  2. no_timestamps - Flag to disable timestamp generation entirely
  3. highlight - Option to highlight transcribed text in output

  Additional Features:

  1. best_of - Number of best candidates to consider for beam search variations
  2. verbose - Enable verbose output for detailed logging

  These parameters provide flexibility in controlling model behavior, performance characteristics, and output formats when using MLX-Whisper for audio transcription tasks.
